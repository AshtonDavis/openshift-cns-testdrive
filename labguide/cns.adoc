:experimental:

## Container-Native Storage Concepts
In this lab we are going to provide a view 'under the hood' of OpenShift
`PersistentVolumes` provided by CNS. For this purpose we will examine volumes
leveraged by example applications using different volume access modes.

### How Container-Native Storage runs

Make sure you are logged on as the super user in the `{{CNS_NAMESPACE}}`:

----
oc login -u system:admin -n {{CNS_NAMESPACE}}
----

Container-Native Storage is GlusterFS running in containers, specifically in pods managed by OpenShift. We have looked at the pods making up the storage cluster already in the introduction chapter:

----
oc get pods -o wide -n {{ CNS_NAMESPACE }}
----

Which yields:

----
NAME              READY     STATUS    RESTARTS   AGE       IP              NODE
glusterfs-storage-37vn8   1/1       Running   0          3m       {{NODE1_INTERNAL_IP}}         {{NODE1_INTERNAL_FQDN}} <1>
glusterfs-storage-cq68l   1/1       Running   0          3m       {{NODE2_INTERNAL_IP}}         {{NODE2_INTERNAL_FQDN}} <1>
glusterfs-storage-m9fvl   1/1       Running   0          3m       {{NODE3_INTERNAL_IP}}         {{NODE3_INTERNAL_FQDN}} <1>
heketi-storage-1-cd032    1/1       Running   0          1m       {{INFRA_INTERNAL_IP}}         {{INFRA_INTERNAL_FQDN}} <2>
----
<1> CNS *Pods*, with each of the designated nodes running exactly one.
<2> heketi API frontend pod

[NOTE]
====
The exact *pod* names will be different in your environment, since they are
auto-generated. Also the heketi *pod* might run on any node.
====

The CNS *Pods* use the host's network and block devices to run the
software-defined storage system. See schematic below for a visualization.

.GlusterFS pods in CNS in detail.
image::cns_diagram_pod.png[]

heketi is a component that will exposes an API into the storage system for
OpenShift. This allows OpenShift to dynamically allocate storage from CNS in a
programmatic fashion. See below for a visualization. Note that for simplicity,
in our example heketi runs on the OpenShift application nodes, not on the
infrastructure node.

.heketi pod running in CNS
image::cns_diagram_heketi.png[]

#### Examine heketi
To expose heketi's API outside of in OpenShift for administrators (for monitoring and maintenance) next to a *Service* named _heketi-storage_ a *Route* has been set up:

----
oc get service,route
----

You will see something like:

----
NAME      CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
heketi    172.30.5.231   <none>        8080/TCP   31m

NAME      HOST/PORT                                               PATH      SERVICES   PORT      TERMINATION   WILDCARD
heketi    heketi-storage-{{CNS_NAMESPACE}}.{{OCP_ROUTING_SUFFIX}}             heketi     <all>                   None
----

You may verify external availability of this API and heketi being alive with a trivial health check:

----
curl -w "\n" http://heketi-storage-{{CNS_NAMESPACE}}.{{OCP_ROUTING_SUFFIX}}/hello
----

This should return (likely without a line break)

----
Hello from Heketi
----

This how the heketi API is made available to both external clients, like `heketi-cli` which we examined in the introduction. But mainly it is leveraged by OpenShift to provision storage dynamically. Let's look at this use case.

### A Simple CNS Use Case

We are going to deploy a sample application that ships with OpenShift which
creates a PVC as part of the deployment. Log on to the system as
`fancyuser1`, using the password `openshift` and create a project with the
name `my-database-app`.

#### Create/Deploy the Application

----
oc login -u fancyuser1 -p openshift
oc new-project my-database-app
----

The example applications ships in form of ready-to-use resource templates. Enter
the following command to look at the template for a sample Ruby on Rails
application with a PostgreSQL database:

----
oc get template/rails-pgsql-persistent -n openshift
----

This template creates a Rails Application instance which mimics a very basic
weblog. The articles and comments are saved in a PostgreSQL database which runs
in another pod.

As part of the resource template a PVC is issued in YAML. Run the following command to `grep` the relavant part:


----
oc get template/rails-pgsql-persistent -n openshift -o yaml | grep PersistentVolumeClaim -A8
----

This show's the basic structure of a `PersistentVolumeClaim`:

[source,yaml]
----
kind: PersistentVolumeClaim
metadata:
  name: ${DATABASE_SERVICE_NAME}
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: ${VOLUME_CAPACITY}
----

This will request a *PersistentVolume* in `RWO` mode. Storage provided in this mode can only be mounted by a single pod at a time. For a database that is usually what you want.
The requested capacity under `spec.resources.requests.storage` is coming in via a parameter when the template is parsed. This is how storage is _requested_.

Using persistent storage is done via a `PersistentVolume` provided in response to this `PersistentVolumeClaim`. A `PersistentVolume` is a representation of some physical storage capacity provisioned by the backing storage system.
It will supply the PostgreSQL pod with persistent storage with the mount point `/var/lib/pgsql/data`.

You can see this when inspecting how the pod is described as part of the `DeploymentConfig`:

----
oc get template/rails-pgsql-persistent -n openshift -o yaml | grep mountPath -B60 -A5
----

Will show:


[source,yaml]
----
- apiVersion: v1
  kind: DeploymentConfig
  metadata:
    annotations:
      description: Defines how to deploy the database
      template.alpha.openshift.io/wait-for-ready: "true"
    name: ${DATABASE_SERVICE_NAME}
  spec:
    replicas: 1
    selector:
      name: ${DATABASE_SERVICE_NAME}
    strategy:
      type: Recreate
    template:
      metadata:
        labels:
          name: ${DATABASE_SERVICE_NAME}
        name: ${DATABASE_SERVICE_NAME}
      spec:
        containers:
        - env:
          - name: POSTGRESQL_USER
            valueFrom:
              secretKeyRef:
                key: database-user
                name: ${NAME}
          - name: POSTGRESQL_PASSWORD
            valueFrom:
              secretKeyRef:
                key: database-password
                name: ${NAME}
          - name: POSTGRESQL_DATABASE
            value: ${DATABASE_NAME}
          - name: POSTGRESQL_MAX_CONNECTIONS
            value: ${POSTGRESQL_MAX_CONNECTIONS}
          - name: POSTGRESQL_SHARED_BUFFERS
            value: ${POSTGRESQL_SHARED_BUFFERS}
          image: ' '
          livenessProbe:
            initialDelaySeconds: 30
            tcpSocket:
              port: 5432
            timeoutSeconds: 1
          name: postgresql
          ports:
          - containerPort: 5432
          readinessProbe:
            exec:
              command:
              - /bin/sh
              - -i
              - -c
              - psql -h 127.0.0.1 -U ${POSTGRESQL_USER} -q -d ${POSTGRESQL_DATABASE}
                -c 'SELECT 1'
            initialDelaySeconds: 5
            timeoutSeconds: 1
          resources:
            limits:
              memory: ${MEMORY_POSTGRESQL_LIMIT}
          volumeMounts:
          - mountPath: /var/lib/pgsql/data <1>
            name: ${DATABASE_SERVICE_NAME}-data <2>
        volumes:
        - name: ${DATABASE_SERVICE_NAME}-data <2>
          persistentVolumeClaim:
            claimName: ${DATABASE_SERVICE_NAME} <3>
----
<1> The mount path where the persistent storage should appear inside the container
<2> The name of the volume known by the container
<3> The `PersistentVolumeClaim` from which this volume should come from

[TIP]
====
In the above snipped you see there are even more parameters in this template. If you want to see more about the parameters or other details of this template,
you can execute the following:

----
oc describe template rails-pgsql-persistent -n openshift
----
====

The following diagram sums up how storage get's provisioned in OpenShift and depicts the relationship of `PersistentVolumes`, `PersistentVolumeClaims` and `StorageClasses`:

.OpenShift Storage Framework.
[caption="OpenShift Persistent Volume Framework", link=cns_diagram_pvc.png]
image::cns_diagram_pvc.png[]

Let's try it out. The storage size parameter in the template is called `VOLUME_CAPACITY`. The `new-app` command will again handle processing and interpreting a *Template* into the appropriate OpenShift objects. We will specify that we want _5Gi_ of storage as part of deploying a new app from the template as follows:

----
oc new-app rails-pgsql-persistent -p VOLUME_CAPACITY=5Gi
----

[NOTE]
====
The `new-app` command will automatically check for templates in the special
`openshift` namespace. In fact, `new-app` tries to do quite a lot of interesting
automagic things, including code introspection when pointed at code
repositories. It is a developer's good friend.
====

You will then see something like the following:

----
--> Deploying template "openshift/rails-pgsql-persistent" to project my-database-app

     Rails + PostgreSQL (Persistent)
     ---------
     An example Rails application with a PostgreSQL database. For more information about using this template, including OpenShift considerations, see https://github.com/openshift/rails-ex/blob/master/README.md.

     The following service(s) have been created in your project: rails-pgsql-persistent, postgresql.

     For more information about using this template, including OpenShift considerations, see https://github.com/openshift/rails-ex/blob/master/README.md.


     * With parameters:
        * Name=rails-pgsql-persistent
        * Namespace=openshift
        * Memory Limit=512Mi
        * Memory Limit (PostgreSQL)=512Mi
        * Volume Capacity=5Gi
        * Git Repository URL=https://github.com/openshift/rails-ex.git
        * Git Reference=
        * Context Directory=
        * Application Hostname=
        * GitHub Webhook Secret=yGhTIuuUjH7JHClrCtYYbY2FdtT0RF5oxA77tGWO # generated
        * Secret Key=8phdjyreu8vaai84ffmvyw18vc3awvgje1c4mw42uplrcvf0dbdyvy1gav4d8dpqwd340l3r6m2otas7eat1cdixpxv65d7rbdbmjhma2jmf2wf0darnou8hhn56ecq # generated
        * Application Username=openshift
        * Application Password=secret
        * Rails Environment=production
        * Database Service Name=postgresql
        * Database Username=userP8B # generated
        * Database Password=USrJhqh6 # generated
        * Database Name=root
        * Maximum Database Connections=100
        * Shared Buffer Amount=12MB
        * Custom RubyGems Mirror URL=

--> Creating resources ...
    secret "rails-pgsql-persistent" created
    service "rails-pgsql-persistent" created
    route "rails-pgsql-persistent" created
    imagestream "rails-pgsql-persistent" created
    buildconfig "rails-pgsql-persistent" created
    deploymentconfig "rails-pgsql-persistent" created
    persistentvolumeclaim "postgresql" created
    service "postgresql" created
    deploymentconfig "postgresql" created
--> Success
    Build scheduled, use 'oc logs -f bc/rails-pgsql-persistent' to track its progress.
    Run 'oc status' to view your app.
----

Go back to the OpenShift web console:

*{{WEB_CONSOLE_URL}}*

Make sure you are logged in as _fancyuser1_ and find your newly created project
`my-database-app`. You can now follow the deployment process here. The deployment is complete when both the PostgreSQL pod and the Ruby application pod have one healthy instance (rings are dark, solid blue).

[NOTE]
====
It may take up to 5 minutes for the deployment to complete.
====

On the CLI, you should now also see a PVC that has been issued and now being in the _Bound_
state.

----
oc get pvc
----

You will see something like:

----
NAME         STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS        AGE
postgresql   Bound     pvc-6de8449e-3f34-11e8-87ea-0298f449cc4c   5Gi        RWO            {{ CNS_STORAGECLASS }}   4m
----

Alternatively, in the web console, check the *"Storage"* menu.

[TIP]
====
This PVC has been automatically fulfilled by CNS because the `{{ CNS_NAMESPACE }}` *StorageClass* was set up as the system-wide default as part of the installation. The responsible parameter in the inventory file was: `openshift_storage_glusterfs_storageclass_default=true`
====

#### Try the Application
Now go ahead and try out the application. The overview page in the OpenShift web console will tell you the *Route* which has been deployed as well. Otherwise get it on the CLI like this:

----
oc get route
----

You will see something like:

----
NAME                     HOST/PORT                                                      PATH      SERVICES                 PORT      TERMINATION   WILDCARD
rails-pgsql-persistent   rails-pgsql-persistent-my-database-app.{{OCP_ROUTING_SUFFIX}}            rails-pgsql-persistent   <all>                   None
----

Following this output, point your browser to:

*http://rails-pgsql-persistent-my-database-app.{{OCP_ROUTING_SUFFIX}}/articles*

The username/password to create articles and comments is by default
'_openshift_'/'_secret_'.

You should be able to successfully create articles and comments. When they are
saved they are actually saved in the PostgreSQL database which stores it's table
spaces on a GlusterFS volume provided by CNS.

[NOTE]
====
This application's template included a *Route* object definition, which is why
the *Service* was automatically exposed. This is a good practice.
Note how the actual application is hosted under the */articles* path of the URL.
====

#### Explore the underlying CNS artifacts
Now let's take a look at how this was deployed on the GlusterFS side. First you
need to acquire necessary permissions:

----
oc login -u system:admin
----

Select the example project of the user `fancyuser1` if not already/still selected:

----
oc project my-database-app
----

Look at the PVC to determine the PV:

----
oc get pvc
----

You will see the PVC being in `BOUND` state and the name of the PV in the `VOLUME` column it has been bound to:

----
NAME         STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS        AGE
postgresql   Bound     pvc-6de8449e-3f34-11e8-87ea-0298f449cc4c   5Gi        RWO            glusterfs-storage   144m
----

[NOTE]
====
Your PV name will be different as it's dynamically generated. A lot of the following things contain dynamically generated names.
*Use the supplied bash shortcuts to ease copy & paste.*
====

Here's a little bash shortcut to store the name of the PVC in a Bash environment variable:

[source,bash]
----
export PGSQL_PV_NAME=$(oc get pvc/postgresql -o jsonpath="{.spec.volumeName}" -n my-database-app)
echo $PGSQL_PV_NAME
----

Look at the details of the PV bound to the PVC, in this case
`pvc-6de8449e-3f34-11e8-87ea-0298f449cc4c` (your's will be different, use the bash variable):

[source,bash]
----
oc describe pv $PGSQL_PV_NAME
----

You will see something like:

----
Name:		pvc-6de8449e-3f34-11e8-87ea-0298f449cc4c <1>
Labels:		<none>
StorageClass:	{{ CNS_STORAGECLASS }}
Status:		Bound
Claim:		my-database-app/postgresql
Reclaim Policy:	Delete
Access Modes:	RWO
Capacity:	5Gi
Message:
Source:
    Type:		Glusterfs (a Glusterfs mount on the host that shares a pod's lifetime)
    EndpointsName:	glusterfs-dynamic-postgresql
    Path:		vol_e8fe7f46fedf7af7628feda0dcbf2f60 <2>
    ReadOnly:		false
No events.
----
<1> The unique name of this PV in the system OpenShift refers to
<2> The unique volume name backing the PV known to GlusterFS


Note the GlusterFS volume name, in this case *vol_e8fe7f46fedf7af7628feda0dcbf2f60*. The following is another Bash shortcut to store the name of the GlusterFS volume backing the `PersistentVolume`:

[source,bash]
----
export PGSQL_GLUSTER_VOLUME=$(oc get pv $PGSQL_PV_NAME -o jsonpath='{.spec.glusterfs.path}')
echo $PGSQL_GLUSTER_VOLUME
----

Now let's switch to the namespace we used for CNS deployment:

----
oc project {{ CNS_NAMESPACE }}
----

Look at the GlusterFS pods running and pick one (which one is not important):

----
oc get pods -o wide -l glusterfs=storage-pod
----

You will see something like:

----
NAME                      READY     STATUS    RESTARTS   AGE      IP                    NODE
glusterfs-storage-37vn8   1/1       Running   0          3m       {{NODE1_INTERNAL_IP}}         {{NODE1_INTERNAL_FQDN}}
glusterfs-storage-cq68l   1/1       Running   0          3m       {{NODE2_INTERNAL_IP}}         {{NODE2_INTERNAL_FQDN}}
glusterfs-storage-m9fvl   1/1       Running   0          3m       {{NODE3_INTERNAL_IP}}         {{NODE3_INTERNAL_FQDN}}
----

We are now going to select the first pod (which one doesn't really matter) and, store it's IP address in above example that is: *{{NODE1_INTERNAL_IP}}* of pod *glusterfs-storage-37vn8*.

Again, for easy copy and paste some Bash shortcuts:

[source,bash]
----
export FIRST_GLUSTER_POD=$(oc get pods -o jsonpath='{.items[0].metadata.name}' -l glusterfs=storage-pod)
export FIRST_GLUSTER_IP=$(oc get pods -o jsonpath='{.items[0].status.podIP}' -l glusterfs=storage-pod)
echo $FIRST_GLUSTER_POD
echo $FIRST_GLUSTER_IP
----

We will again use the `oc rsh` facility to log on to the selected GlusterFS pod which has the GlusterFS CLI utilities installed. This time we use the non-interactive mode which immediately drops out after executing the supplied command.

Query GlusterFS from inside the first GlusterFS pod for all known volumes:

[source,bash]
----
oc rsh $FIRST_GLUSTER_POD gluster volume list
----

You will immediately drop back out to your shell and you will see something like:

----
heketidbstorage <1>
vol_e8fe7f46fedf7af7628feda0dcbf2f60 <2>
vol_5e1cd71070734a3b02f58d822f89486a
vol_f2e8fda1d42a41efabbb4d4a3b4a5659
----
<1> A special volume dedicated to heketi's internal database.
<2> The volume backing the PV of the PostgreSQL database we asked you to remember.

Query GlusterFS about the topology of this volume:

[source,bash]
----
oc rsh $FIRST_GLUSTER_POD gluster volume info $PGSQL_GLUSTER_VOLUME
----

You will see something like:

----
Volume Name: vol_e8fe7f46fedf7af7628feda0dcbf2f60
Type: Replicate
Volume ID: c2bedd16-8b0d-432c-b9eb-4ab1274826dd
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 3 = 3
Transport-type: tcp
Bricks:
Brick1: {{NODE2_INTERNAL_IP}}:/var/lib/heketi/mounts/vg_63b05bee6695ee5a63ad95bfbce43bf7/brick_aa28de668c8c21192df55956a822bd3c/brick
Brick2: {{NODE1_INTERNAL_IP}}:/var/lib/heketi/mounts/vg_0246fd563709384a3cbc3f3bbeeb87a9/brick_684a01f8993f241a92db02b117e0b912/brick <1>
Brick3: {{NODE3_INTERNAL_IP}}:/var/lib/heketi/mounts/vg_5a8c767e65feef7455b58d01c6936b83/brick_25972cf5ed7ea81c947c62443ccb308c/brick
Options Reconfigured:
transport.address-family: inet
performance.readdir-ahead: on
nfs.disable: on
----
<1> According to the output of `oc get pods -o wide` this is the container we are logged on to.

[NOTE]
====
Identify the right brick by looking at the host IP of the GlusterFS pod
you have just logged on to. `oc get pods -o wide` will give you this
information. The host's IP will be noted next to one of the bricks.
====

GlusterFS created this volume as a 3-way replica set across all GlusterFS pods,
in therefore across all your OpenShift App nodes running CNS. Data written to such a replica volume is replicated 3 times to all *bricks*.
*Bricks* are local storage in GlusterFS nodes, usually backed by a local SAS disk or NVMe device. Each node exposes it's local storage via the GlusterFS protocol. The brick itself is simply a directory on a block device formatted with XFS - hence you can look with a simple `ls` command at how the data is stored actually in each brick.

For easy copy and paste, here's another bash shortcut to extract the brick directory path of our PostgreSQL volume from the fist GlusterFS pod in the list:

[source,bash]
export PGSQL_GLUSTER_BRICK=$(echo -n $(oc rsh $FIRST_GLUSTER_POD gluster vol info $PGSQL_GLUSTER_VOLUME | grep $FIRST_GLUSTER_IP) | cut -d ':' -f 3 | tr -d $'\r' )
echo $PGSQL_GLUSTER_BRICK

You can look at the brick directory of the first GlusterFS pod and see how GlusterFS stores the files from the clients in a brick:

[source,bash]
----
oc rsh $FIRST_GLUSTER_POD ls -ahl $PGSQL_GLUSTER_BRICK
----

You will see something like:

----
total 16K
drwxrwsr-x.   5 root       2001   57 Jun  6 14:44 .
drwxr-xr-x.   3 root       root   19 Jun  6 14:44 ..
drw---S---. 263 root       2001 8.0K Jun  6 14:46 .glusterfs
drwxr-sr-x.   3 root       2001   25 Jun  6 14:44 .trashcan
drwx------.  20 1000080000 2001 8.0K Jun  6 14:46 userdata
----

Dig a bit deeper, try looking at the `userdata` folder:

[source,bash]
----
oc rsh $FIRST_GLUSTER_POD ls -ahl $PGSQL_GLUSTER_BRICK/userdata
----

You will see the PostgreSQL database folder structure:

----
total 68K
drwx------. 20 1000080000 2001 8.0K Jun  6 14:46 .
drwxrwsr-x.  5 root       2001   57 Jun  6 14:44 ..
-rw-------.  2 1000080000 root    4 Jun  6 14:44 PG_VERSION
drwx------.  6 1000080000 root   54 Jun  6 14:46 base
drwx------.  2 1000080000 root 8.0K Jun  6 14:47 global
drwx------.  2 1000080000 root   18 Jun  6 14:44 pg_clog
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_commit_ts
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_dynshmem
-rw-------.  2 1000080000 root 4.6K Jun  6 14:46 pg_hba.conf
-rw-------.  2 1000080000 root 1.6K Jun  6 14:44 pg_ident.conf
drwx------.  2 1000080000 root   32 Jun  6 14:46 pg_log
drwx------.  4 1000080000 root   39 Jun  6 14:44 pg_logical
drwx------.  4 1000080000 root   36 Jun  6 14:44 pg_multixact
drwx------.  2 1000080000 root   18 Jun  6 14:46 pg_notify
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_replslot
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_serial
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_snapshots
drwx------.  2 1000080000 root    6 Jun  6 14:46 pg_stat
drwx------.  2 1000080000 root   84 Jun  6 15:16 pg_stat_tmp
drwx------.  2 1000080000 root   18 Jun  6 14:44 pg_subtrans
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_tblspc
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_twophase
drwx------.  3 1000080000 root   60 Jun  6 14:44 pg_xlog
-rw-------.  2 1000080000 root   88 Jun  6 14:44 postgresql.auto.conf
-rw-------.  2 1000080000 root  21K Jun  6 14:46 postgresql.conf
-rw-------.  2 1000080000 root   46 Jun  6 14:46 postmaster.opts
-rw-------.  2 1000080000 root   89 Jun  6 14:46 postmaster.pid
----

You are looking at the PostgreSQL internal data file structure from the
perspective of the GlusterFS server side. It's a normal local filesystem here.

Clients, like the OpenShift nodes and their application pods talk to this
set of replicated brick storage via the GlusterFS protocol. Which abstracts the 3-way replication behind a single FUSE mount point - this is called a `volume` in GlusterFS.
When a pod starts that mounts storage from a `PV` backed by GlusterFS, OpenShift will mount the GlusterFS volume on the right app node and then _bind-mount_ this directory to the right pod. This is happening transparently to the application inside the pod and looks like a normal local filesystem.

### Providing Scalable, Shared Storage With CNS
So far only very few options, like the basic NFS support, existed to provide a
*PersistentVolume* to more than one container at once. The access mode used for
this is `ReadWriteMany`. Traditional block-based storage solutions are not able
to do this.

Also, once provisioned, most storage cannot easily be resized.

With CNS these capabilities are now available to all OpenShift deployments, no
matter where they are deployed. To illustrate the benefit of these, we will
deploy a PHP application, a file uploader that has multiple front-end instances
sharing a common storage repository.

#### Deploy the File Uploader Application
First log back in as `fancyuser1` using the password `openshift` and create a new project:

----
oc login -u fancyuser1 -p openshift
oc new-project my-shared-storage
----

Next deploy the example PHP application called `file-uploader`:

----
oc new-app openshift/php:7.0~https://github.com/christianh814/openshift-php-upload-demo --name=file-uploader
----

You will see something like:

----
--> Found image a1ebebb (6 weeks old) in image stream "openshift/php" under tag "7.0" for "openshift/php:7.0"

    Apache 2.4 with PHP 7.0
    -----------------------
    Platform for building and running PHP 7.0 applications

    Tags: builder, php, php70, rh-php70

    * A source build using source code from https://github.com/christianh814/openshift-php-upload-demo will be created
      * The resulting image will be pushed to image stream "file-uploader:latest"
      * Use 'start-build' to trigger a new build
    * This image will be deployed in deployment config "file-uploader"
    * Port 8080/tcp will be load balanced by service "file-uploader"
      * Other containers can access this service through the hostname "file-uploader"

--> Creating resources ...
    imagestream "file-uploader" created
    buildconfig "file-uploader" created
    deploymentconfig "file-uploader" created
    service "file-uploader" created
--> Success
    Build scheduled, use 'oc logs -f bc/file-uploader' to track its progress.
    Run 'oc status' to view your app.
----

Watch and wait for the application to be deployed:

----
oc logs -f bc/file-uploader
----

You will see something like:

----
Cloning "https://github.com/christianh814/openshift-php-upload-demo" ...
	Commit:	7508da63d78b4abc8d03eac480ae930beec5d29d (Update index.html)
	Author:	Christian Hernandez <christianh814@users.noreply.github.com>
	Date:	Thu Mar 23 09:59:38 2017 -0700
---> Installing application source...
Pushing image 172.30.120.134:5000/my-shared-storage/file-uploader:latest ...
Pushed 0/5 layers, 2% complete
Pushed 1/5 layers, 20% complete
Pushed 2/5 layers, 40% complete
Push successful
----

The command prompt returhs out of the tail mode once you see _Push successful_.

[NOTE]
====
This use of the `new-app` command directly asked for application code to be
built and did not involve a template. That's why created only a *single Pod* deployment with a *Service* and no *Route*.
====

Let's make our application production ready by exposing it via a `Route` and scale to 3 instances for high availability:

----
oc expose svc/file-uploader
oc scale --replicas=3 dc/file-uploader
----

Now, check the *Route* that has been created:

----
oc get route
----

You will see something like:

----
NAME                     HOST/PORT                                                      PATH      SERVICES                 PORT       TERMINATION   WILDCARD
file-uploader            file-uploader-my-shared-storage.{{ OCP_ROUTING_SUFFIX}}                      file-uploader            8080-tcp                 None
...
----

Point your browser to the web application using the URL advertised by the route
(http://file-uploader-my-shared-storage.{{ OCP_ROUTING_SUFFIX}})

The web app simply lists all file previously uploaded and offers the ability
to upload new ones as well as download the existing data. Right now there is
nothing.

Select an arbitrary file from your local machine and upload it to the app.

.A simple PHP-based file upload tool
image::uploader_screen_upload.png[]

Once done click *_List uploaded files_* to see the list of all currently uploaded files.

Do you see it? Don't worry if you don't.

Change back to the command line and look at the running pods.

----
oc get pods -l app=file-uploader
----

You will see 3 pods running:

----
NAME                             READY     STATUS      RESTARTS   AGE
file-uploader-1-k2v0d            1/1       Running     0          1m
file-uploader-1-sz49r            1/1       Running     0          1m
file-uploader-1-xjg9f            1/1       Running     0          1m
...
----


Now let's look back at where this file got stored inside the pods. Again use the `oc rsh` utility to execute an `ls` command on the `upload` directory that the PHP code uses to store the files:

[source,bash,role=copypaste]
----
oc rsh file-uploader-1-k2v0d ls -hl uploaded
oc rsh file-uploader-1-sz49r ls -hl uploaded
oc rsh file-uploader-1-xjg9f ls -hl uploaded
----

[NOTE]
====
The exact name of the *Pods* will be different in your environment. Use the names from the `oc get pods` output above.
====

You will see only one of the pods has the uploaded file
----
total 144K
-rw-r--r--. 1 1000180000 root 141K Apr 18 10:01 shakespeare-romeo-48.txt
----
----
total 0
----
----
total 0
----

Why is that? These pods currently does not use any persistent storage. They stores the file locally in the container root file system. That means the application cannot effectively be scaled since the pods do not share data and every client would see different uploaded files (in doubt, try it with a second _Icognito_ browser session).

[CAUTION]
====
Never attempt to store persistent data in a *Pod*. *Pods* and their containers are ephemeral by definition, and any stored data will be lost as soon as the *Pod* terminates for whatever reason.
====

The app is of course not usable like this. We can fix this by providing shared
storage to this app.

You can create a *PersistentVolumeClaim* and attach it into an application with
the `oc volume` command. Execute the following

[source]
----
oc volume dc/file-uploader --add --name=my-shared-storage \
-t pvc --claim-mode=ReadWriteMany --claim-size=1Gi \
--claim-name=my-shared-storage --mount-path=/opt/app-root/src/uploaded
----

Like with the `mapit` application in "_Application Management Basics_" chapter, this command will:

* create a *PersistentVolumeClaim*
* update the *DeploymentConfig* to include a `volume` definition
* update the *DeploymentConfig* to attach a `volumemount` into the specified
  `mount-path`
* cause a new deployment of the application *Pods*

For more information on what `oc volume` is capable of, look at its help output
with `oc volume -h`. Now, let's look at the result of adding the volume:

----
oc get pvc
----

You will see something like:

----
NAME                STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
my-shared-storage   Bound     pvc-62aa4dfe-4ad2-11e7-b56f-2cc2602a6dc8   1Gi        RWX           22s
...
----

Notice the `ACCESSMODE` being set to *RWX* (short for `ReadWriteMany`, equivalent to "shared storage"). Without this `ACCESSMODE`, OpenShift will not attempt to attach multiple *Pods* to the same *PersistentVolume* reliably. If you attempt to scale up deployments that are using `ReadWriteOnce` storage, they will actually all become co-located on the same node.

The app has now re-deployed (in a rolling fashion) with the new settings - all
pods will mount the volume identified by the PVC under
`/opt/app-root/src/upload`.

Check you have a new set of pods:

----
oc get pods -l app=file-uploader
----

You will see something like:

----
NAME                             READY     STATUS      RESTARTS   AGE
file-uploader-2-jd22b   1/1       Running   0          2m
file-uploader-2-kw9lq   1/1       Running   0          2m
file-uploader-2-xbz24   1/1       Running   0          2m

----

Try it out in your file uploader web application using your browser: upload new files and watch them being visible from within all application pods.

[CAUTION]
====
Where is my previously uploaded file?

Since the pod redeployed the file has been lost with the previous container's root filesystem going away as part of the configuration update. One more reason to provide persistent storage!
====

Once done, return to the command line and look at the contents of pods:

[source,bash,role=copypaste]
----
oc rsh file-uploader-2-jd22b
sh-4.2$ ls -lh uploaded
total 16K
-rw-r--r--. 1 1000080000 root 16K May 26 10:21 cns-deploy-4.0.0-15.el7rhgs.x86_64.rpm.gz
sh-4.2$ exit
exit
oc rsh file-uploader-2-kw9lq
sh-4.2$ ls -lh uploaded
-rw-r--r--. 1 1000080000 root 16K May 26 10:21 cns-deploy-4.0.0-15.el7rhgs.x86_64.rpm.gz
sh-4.2$ exit
exit
oc rsh file-uploader-2-xbz24
sh-4.2$ ls -lh uploaded
-rw-r--r--. 1 1000080000 root 16K May 26 10:21 cns-deploy-4.0.0-15.el7rhgs.x86_64.rpm.gz
sh-4.2$ exit
----

That's it. You have successfully provided shared storage to pods throughout the
entire system, therefore avoiding the need for data to be replicated at the
application level to each pod.

With CNS this is available wherever OpenShift is deployed with no external
dependency like NFS.

### Increasing volume capacity

What however happens when the volume is running full?

Let's try it. Run the following command to fill up the currently 1GiB of free space in the persistent volume. Since it's shared, you can use any the 3 file-uploader pods:

[source,bash,role=copypaste]
----
oc rsh file-uploader-2-jd22b dd if=/dev/zero of=uploaded/bigfile bs=1M count=1000
----

The result after some 30 seconds is:
----
d: error writing 'uploaded/bigfile': Input/output error
dd: closing output file 'uploaded/bigfile': Input/output error
----

Oops. The file system seems to have a problem. Let's check it:
[source,bash,role=copypaste]
----
oc rsh file-uploader-2-jd22b df -h /opt/app-root/src/uploaded
----

Houston, we have a problem - clearly the file system is full:

----
Filesystem                                      Size  Used Avail Use% Mounted on
10.0.1.36:vol_6320cd6974d8573f49f85a5d7255a7f2 1019M 1019M     0 100% /opt/app-root/src/uploaded
----

If you were to try uploading another file via the web application it would fail with something along the lines:

----
[...]
failed to open stream: No space left on device in /opt/app-root/src/upload.php on line 26
[...]
----

Fortunately that is easy to fix for the user or owner of the app, even without administrator intervention.

Use the `oc edit` command to edit the `PersistentVolumeClaim` that we used to generate the `PersistentVolume`:

----
oc edit pvc my-shared-storage
----

You end up in a `vi` session editing the `PVC` object properties in YAML. Go to line that says `storage: 1Gi` below spec -> resources -> requests and increase to `5Gi` like shown below:

[source,yaml]
----
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  annotations:
    pv.kubernetes.io/bind-completed: "yes"
    pv.kubernetes.io/bound-by-controller: "yes"
    volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/glusterfs
  creationTimestamp: 2018-04-18T10:17:24Z
  name: my-shared-storage
  namespace: my-shared-storage
  resourceVersion: "41960"
  selfLink: /api/v1/namespaces/my-shared-storage/persistentvolumeclaims/my-shared-storage
  uid: b0544244-42f1-11e8-8f68-02f9630bd644
spec:
  accessModes:
  - ReadWriteMany
  resources:
    requests:
      storage: 5Gi <1>
  storageClassName: glusterfs-storage
  volumeName: pvc-b0544244-42f1-11e8-8f68-02f9630bd644
status:
  accessModes:
  - ReadWriteMany
  capacity:
    storage: 1Gi
  phase: Bound
----
<1> Set this to *5Gi*

Exit out of `vi` mode with the `:wq` command.

[TIP]
====
Upon writing the file the `oc edit` command will update the `PersistentVolumeClaim` definition in OpenShift. This way of ad-hoc editing works with many objects in OpenShift.
====

Give it a couple of seconds and then check the filesystem again:

[source,bash,role=copypaste]
----
oc rsh file-uploader-2-jd22b df -h /opt/app-root/src/uploaded
----

The situation should look much better now:

----
Filesystem                                      Size  Used Avail Use% Mounted on
10.0.1.36:vol_6320cd6974d8573f49f85a5d7255a7f2  5.0G  1.1G  4.0G  21% /opt/app-root/src/uploaded
----

### Increasing Storage Capacity in CNS

At some point the overall CNS cluster capacity may need to be expanded. There are two ways of how to to increase the storage capacity offered by CNS. Either by adding additional nodes with storage ton existing CNS cluster or by adding additional storage devices to the existing nodes of a running CNS cluster.

You also have the option to deploy a second CNS cluster, which is what we are doing next:

#### Adding a new CNS cluster

Adding an additional CNS cluster this way is a three-step process:

1. Scale-out the OpenShift cluster with additional nodes
2. Initialize a new CNS cluster out of those additional nodes
3. Set up a `StorageClass` to make this new cluster accessible.

Fortunately most of these steps are prepared already. In the preceding link:infra-mgmt-basics["Infrastructure Management Module"] you have already
added a second set of 3 nodes to the OpenShift cluster.
These have an unused storage device available, which we will use for CNS.

For the second step, you use the `heketi-cli` utility.

The following action require elevated privileges in OpenShift. Login as cluster
admin and change to the CNS namespace:

----
oc login -u system:admin
oc project {{ CNS_NAMESPACE }}
----

First, identify the newly added nodes - the easiest way is to look at their uptime:

----
oc get nodes
----

You will see something like:

----
NAME                                          STATUS    ROLES     AGE
{{INFRA_INTERNAL_FQDN}}    Ready     <none>    5h
{{MASTER_INTERNAL_FQDN}}   Ready     master    5h
{{NODE1_INTERNAL_FQDN}}   Ready     compute   5h
{{NODE2_INTERNAL_FQDN}}   Ready     compute   5h
{{NODE3_INTERNAL_FQDN}}   Ready     compute   5h
{{NODE4_INTERNAL_FQDN}}   Ready     compute   5h <1>
{{NODE5_INTERNAL_FQDN}}   Ready     compute   5h <1>
{{NODE6_INTERNAL_FQDN}}   Ready     compute   5h <1>
----
<1> The nodes added in the previous lab

Now we need to make sure, that these new systems have the right firewall ports
opened and some kernel modules loaded. This is because the installation routine did not set up those nodes for running CNS - it's currently not supported to scale CNS clusters with `openshift-ansible`.

For simplicity, we have provided an Ansible playbook that takes care of this. Otherwise these steps are also explaind in the link:https://access.redhat.com/documentation/en-us/container-native_storage/3.9/html-single/container-native_storage_for_openshift_container_platform/#Setting_up_CNS[CNS documentation^].

Execute the playbook `configure-for-cns.yaml` like so:

----
ansible-playbook -i node04,node05,node06, configure-for-cns.yaml
----

Next, add the following label to these nodes in order have the *DaemonSet* that
CNS is based upon schedule new GlusterFS pods on them:

----
oc get daemonset
----

You will see something like:

----
NAME                DESIRED   CURRENT   READY     NODE-SELECTOR           AGE
glusterfs-storage   3         3         3         glusterfs=storage-host  6h
----
<1> The label definition the *DaemonSet* uses to select the nodes which run a
  GlusterFS pod.

[TIP]
====
What's a `DaemonSet` again?

A `DaemonSet` in OpenShift is a special kind of replication controller that ensures that exactly one pod is running on all nodes of a certain kind. the kind of node is determined by a label-selector.
You have already seen `DaemonSets` as part of the Logging deploy in the link:infra-mgmt-basics["Infrastructure Management Module"] controlling the placement of _Fluentd_ pods.
====

----
oc label node/{{NODE4_INTERNAL_FQDN}} glusterfs=storage-host
oc label node/{{NODE5_INTERNAL_FQDN}} glusterfs=storage-host
oc label node/{{NODE6_INTERNAL_FQDN}} glusterfs=storage-host
----

The *DaemonSet* will detect that new nodes have these labels, and GlusterFS
*Pods* will be launched on the newly labeled nodes. Wait for these *Pods* to be
in `Ready` state:

----
oc get pods -o wide -l glusterfs=storage-pod
----

You will see something like:

----
NAME                      READY     STATUS    RESTARTS   AGE      IP                    NODE
glusterfs-storage-3gjc5   1/1       Running   0          1m       {{NODE6_INTERNAL_IP}}         {{NODE6_INTERNAL_FQDN}}  <1>
glusterfs-storage-37vn8   1/1       Running   0          3h       {{NODE1_INTERNAL_IP}}         {{NODE1_INTERNAL_FQDN}}
glusterfs-storage-ng00k   1/1       Running   0          1m       {{NODE4_INTERNAL_IP}}         {{NODE4_INTERNAL_FQDN}}  <1>
glusterfs-storage-cq68l   1/1       Running   0          3m       {{NODE2_INTERNAL_IP}}         {{NODE2_INTERNAL_FQDN}}
glusterfs-storage-zkvfl   1/1       Running   0          1m       {{NODE5_INTERNAL_IP}}         {{NODE5_INTERNAL_FQDN}}  <1>
glusterfs-storage-m9fvl   1/1       Running   0          3m       {{NODE3_INTERNAL_IP}}         {{NODE3_INTERNAL_FQDN}}
----
<1> The newly spawned GlusterFS pods.

[NOTE]
====
It may take up to 120 seconds for the GlusterFS *Pods* to be up and in _Ready_ state.
====

You can also check the `DaemonSet` for the current state:

----
oc get daemonset glusterfs-storage
----

It should display 6 ready pods out of 6 desired pods, one per host:

----
NAME                DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
glusterfs-storage   6         6         6         6            6           glusterfs=storage-host   6h
----

The new *Pods* run GlusterFS uninitialized. That is, they have not formed a
cluster among themselves yet. This is triggered via heketi. If you do not have the environment variables `HEKETI_CLI_USER`, `HEKETI_CLI_SERVER` and `HEKETI_CLI_KEY` anymore you need to set them again so the client can authenticate with the server.

For a change, here is another Bash shortcut to set up the environment variables

----
export HEKETI_POD=$(oc get pods -l glusterfs=heketi-storage-pod -o jsonpath="{.items[0].metadata.name}")
export HEKETI_CLI_SERVER=http://$(oc get route -l glusterfs=heketi-storage-route -o jsonpath='{.items[0].spec.host}')
export HEKETI_CLI_USER=admin
export HEKETI_CLI_KEY=$(oc get pod/$HEKETI_POD -o jsonpath='{.spec.containers[0].env[?(@.name=="HEKETI_ADMIN_KEY")].value}')
----


With the `heketi-cli` client configured we can query for the UUID of the single cluster we have:

----
heketi-cli cluster list
----

You will see:
----
Clusters:
Id:ec7a9c8be8327a54839236791bf7ba24 [file][block]
----

Save this first clusters ID in a Bash variable like so:

----
export FIRST_CNS_CLUSTER_ID=$(heketi-cli cluster list --json | jq -r '.clusters[0]')
----

With this in place we can ask `heketi` to initialize the 3 additional CNS pods and treat it as a second cluster.
There are two ways to do this: manually, one by one using the `cluster create`, `node add` and `device add` commands of `heketi-cli` or describing everything in a JSON structure. Since the former requires dealing with a lot of UUIDs we are going to use the second form.

The JSON structure has already been prepared for you in the file `/opt/lab/support/topology-new.json`:

[source,json]
./opt/lab/support/stopology-new.json
----
{
    "clusters": [
        {
            "nodes": [
                {
                    "node": {
                        "hostnames": {
                            "manage": [
                                "{{NODE4_INTERNAL_FQDN}}"
                            ],
                            "storage": [
                                "{{NODE4_INTERNAL_IP}}"
                            ]
                        },
                        "zone": 1
                    },
                    "devices": [
                        "{{NODE_BRICK_DEVICE}}"
                    ]
                },
                {
                    "node": {
                        "hostnames": {
                            "manage": [
                                "{{NODE5_INTERNAL_FQDN}}"
                            ],
                            "storage": [
                                "{{NODE5_INTERNAL_IP}}"
                            ]
                        },
                        "zone": 2
                    },
                    "devices": [
                        "{{NODE_BRICK_DEVICE}}"
                    ]
                },
                {
                    "node": {
                        "hostnames": {
                            "manage": [
                                "{{NODE6_INTERNAL_FQDN}}"
                            ],
                            "storage": [
                                "{{NODE6_INTERNAL_IP}}"
                            ]
                        },
                        "zone": 3
                    },
                    "devices": [
                        "{{NODE_BRICK_DEVICE}}"
                    ]
                }
            ]
        }
    ]
}
----

This structure contains a JSON list named `clusters` in which a single item with the 3 `nodes` is listed. For each node one supplies the FQDN of the system as well as the IP, and a list of `devices` CNS will use. The `zone` parameter is optional.

You can initialize the second CNS cluster like so:

----
heketi-cli topology load --json=/opt/lab/support/topology-new.json
----

You should see something like the following:
----
Creating cluster ... ID: ca777ae0285ef6d8cd7237c862bd591c
	Allowing file volumes on cluster.
	Allowing block volumes on cluster.
	Creating node {{NODE4_INTERNAL_FQDN}} ... ID: 44b5e2d531e89889c292e28423fedc7c
		Adding device {{NODE_BRICK_DEVICE}} ... OK
	Creating node {{NODE5_INTERNAL_FQDN}} ... ID: c5b12988d5b7e549684e495791d22149
		Adding device {{NODE_BRICK_DEVICE}} ... OK
	Creating node {{NODE6_INTERNAL_FQDN}} ... ID: 6bcf0022657b2b15cdd98f7a60613994
		Adding device {{NODE_BRICK_DEVICE}} ... OK
----

With this you've successfully initialized a second CNS storage cluster that is
managed by a single instance of `heketi`.

[NOTE]
====
Your second cluster's ID will be different for you since it's automatically generated.
====

Save the second cluster's ID in a Bash environment variable:

[source,bash]
----
export SECOND_CNS_CLUSTER_ID=$(heketi-cli cluster list --json | jq -r ".clusters[] | select(contains(\"$FIRST_CNS_CLUSTER_ID\") | not)")
echo $SECOND_CNS_CLUSTER_ID
----

This was step 2. Step 3 is exposing this new CNS cluster in OpenShift by means of a `StorageClass`.

This is really easy since the only difference from the `StorageClass` for the first CNS cluster is the name, and the `clusterid` parameter. `heketi` uses this parameter later to decide on which CNS cluster it will create the requested volume.

You can look at the `StorageClass` for the first cluster like so:

----
oc get storageclass {{ CNS_STORAGECLASS }} -o yaml
----

We could now copy this by saving the output of this command in a file, modify the name, add `clusterid` parameter and set the `is-default-class` value to `false` and then use `oc create -f <file.yaml>` to create the new `StorageClass` object.

Here is a shortcut using the nifty `jq` utility (a JSON manipulator) to do this in a single command line.

[source,bash]
----
oc get storageclass {{ CNS_STORAGECLASS }} -o json \
| jq ".parameters=(.parameters + {\"clusterid\": \"$SECOND_CNS_CLUSTER_ID\"})" \
| jq '.metadata.name = "{{ CNS_STORAGECLASS2 }}"' \
| jq '.metadata.annotations."storageclass.kubernetes.io/is-default-class" = "false"' > glusterfs-storage-second.json
----

You can look at the file now, it should look similar to this:

[source,json]
.glusterfs-storage-second.json
----
{
  "allowVolumeExpansion": true,
  "apiVersion": "storage.k8s.io/v1",
  "kind": "StorageClass",
  "metadata": {
    "annotations": {
      "storageclass.kubernetes.io/is-default-class": "false"
    },
    "creationTimestamp": "2018-04-18T05:16:22Z",
    "name": "glusterfs-storage-second", <1>
    "resourceVersion": "8589",
    "selfLink": "/apis/storage.k8s.io/v1/storageclasses/glusterfs-storage",
    "uid": "a26af25a-42c7-11e8-81f6-02f9630bd644"
  },
  "parameters": {
    "resturl": "http://heketi-storage-{{CNS_NAMESPACE}}.{{OCP_ROUTING_SUFFIX}}",
    "restuser": "admin",
    "secretName": "heketi-storage-admin-secret",
    "secretNamespace": "storage",
    "clusterid": "ca777ae0285ef6d8cd7237c862bd591c" <2>
  },
  "provisioner": "kubernetes.io/glusterfs",
  "reclaimPolicy": "Delete"
}
----
<1> The new name of our second `StorageClass`
<2> The heketi internal ID of the new cluster is used to specifically direct
requests to it. This should contain *your ID* of the second cluster.

----
oc create -f glusterfs-storage-second.json
----

The command should go through without erros.

----
storageclass "glusterfs-storage-second" created
----

Finished. We can now use our new cluster.
For your convenience, there is a *PersistentVolumeClaim* definition file that already has been placed
in `/opt/lab/support` for you:

[source,yaml]
./opt/lab/support/cns-second-pvc.yaml
----
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: my-container-storage-second
  annotations:
    volume.kubernetes.io/storage-class: glusterfs-storage-second
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
----

You can create it with the following:

----
oc create -f /opt/lab/support/cns-second-pvc.yaml
----

This PVC will now be fulfilled by the _{{ CNS_STORAGECLASS2 }}_ *StorageClass*
which specifically directs the requests to the second cluster specified by its
UUID in the `clusterid` parameter of the *StorageClass*.

You can see that this claim is automatically bound:

----
oc get pvc
----

You will see something like:

----
NAME                          STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
my-container-storage-silver   Bound     pvc-5efde23a-901e-11e7-bebd-12eaac0992cc   1Gi        RWO           2m
----

### Other CNS Maintenance Activities
In addition to extending your CNS cluster with additional storage nodes, you may
also want to perform other maintenance activities. For example, if you have
added more block devices to one of your CNS nodes, you may simply wish to add
additional devices to the cluster. Or, if you have degraded physical devices
that need to be replaced, maintained, or eliminated, you may wish to remove
devices from a cluster.

#### Adding Additional Devices to a CNS Cluster
Instead of adding a net-new cluster you can also add additional devices to an
existing cluster. The process is very similar to adding new nodes - loading a
modified topology JSON file via the heketi client.

To illustrate an alternative we are going to use `heketi-cli` tool directly.

The nodes of the second cluster, have an additional, unused storage device
`{{NODE_BRICK_DEVICE2}}`. To add them we need to know their node IDs. + With the
environment variables for `heketi-cli` still set run:

----
heketi-cli node list | grep ca777ae0285ef6d8cd7237c862bd591c
Id:33e0045354db4be29b18728cbe817605	Cluster:ca777ae0285ef6d8cd7237c862bd591c
Id:d8443e7ee8314c0c9fb4d8274a370bbd	Cluster:ca777ae0285ef6d8cd7237c862bd591c
Id:caaed3927e424b22b1a89d261f7617ad	Cluster:ca777ae0285ef6d8cd7237c862bd591c
----

[IMPORTANT]
====
You will need to replace the `grep` with your unique cluster ID. This is the
cluster ID of the second / new CNS cluster that you just created previously, and
used when creating the new `cns-silver` *StorageClass*.
====

For each node in the output (eg: `33e0045354db4be29b18728cbe817605`,
`d8443e7ee8314c0c9fb4d8274a370bbd`, and `caaed3927e424b22b1a89d261f7617ad`), go
ahhead and `device add` the additional block device:

----
heketi-cli device add --name={{NODE_BRICK_DEVICE2}} --node=33e0045354db4be29b18728cbe817605
Device added successfully

heketi-cli device add --name={{NODE_BRICK_DEVICE2}} --node=d8443e7ee8314c0c9fb4d8274a370bbd
Device added successfully

heketi-cli device add --name={{NODE_BRICK_DEVICE2}} --node=caaed3927e424b22b1a89d261f7617ad
Device added successfully
----

[NOTE]
====
The node UUIDs will be different for you since they are automatically generated.
====

You can now verify the presence of these new devices by running:

----
heketi-cli topology info
----

You should see a `/dev/xvde` device present for each of the nodes in the
`cns-silver` cluster.

### Replacing Failed Disks and Nodes

Despite CNS' capability to continue operating transparently to the client in the
face of failing disks and nodes, you soon might want to replace such components
to move out of a degraded state.

For this exercise, let's assume the device `{{NODE_BRICK_DEVICE}}` of your node
{{NODE4_INTERNAL_FQDN}} failed and you need to replace it. You can do that as
long as there is enough spare capacity somewhere else in the cluster,
preferrable but not necessarily in the same failure domain (as specifed in the
topology).

The first step is to, again, determine the CNS node's internal UUID in heketi's
database:

----
heketi-cli topology info | grep -B4 {{NODE4_INTERNAL_FQDN}}
----

You will see something like:

----
	Node Id: 33e0045354db4be29b18728cbe817605
	State: online
	Cluster Id: ca777ae0285ef6d8cd7237c862bd591c
	Zone: 1
	Management Hostname: {{NODE4_INTERNAL_FQDN}}
----

Second, determine the device's UUID by querying the node (indicated above by
`Node Id`):

[source,bash,role=copypaste]
----
heketi-cli node info 33e0045354db4be29b18728cbe817605
----

You will see something like:

----
Node Id: 33e0045354db4be29b18728cbe817605
State: online
Cluster Id: ca777ae0285ef6d8cd7237c862bd591c
Zone: 1
Management Hostname: {{NODE4_INTERNAL_FQDN}}
Storage Hostname: {{NODE4_INTERNAL_IP}}
Devices:
Id:01c94798bf6b1af87974573b420c4dff   Name:{{NODE_BRICK_DEVICE}}           State:online    Size (GiB):9       Used (GiB):1       Free (GiB):8
Id:da91a2f1c9f62d9916831de18cc09952   Name:{{NODE_BRICK_DEVICE2}}           State:online    Size (GiB):9       Used (GiB):1       Free (GiB):8
----

Notice the UUID of the device `{{NODE_BRICK_DEVICE}}` as shown.

[NOTE]
====
The device ID, as well as all other UUIDs in heketi commands are
automatically generated and different in your environment. Please be aware when
copy & pasting.
====

Third, mark the device as offline to stop heketi from further attempts to
allocate space from it:

[source,bash,role=copypaste]
----
heketi-cli device disable 01c94798bf6b1af87974573b420c4dff
----

You will see something like:

----
Device 01c94798bf6b1af87974573b420c4dff is now offline
----

The device is now offline but it's still part of replicated volumes. To remove
it and trigger a self-healing operation in the background issue:

[source,bash,role=copypaste]
----
heketi-cli device remove 01c94798bf6b1af87974573b420c4dff
----

You will see something like:

----
Device 01c94798bf6b1af87974573b420c4dff is now removed
----

This command can take a bit longer as it will go through the topology and search
for the next available device on the same node, in the same failure domain and
in the rest of the cluster (in that order) and trigger a brick-replacement
operation. This way data is re-replicated to another health storage device and
the 3-way replicated storage volume moves out of degraded state.

The device is still lurking around in _failed_ state. To finally get rid of it
issue:

[source,bash,role=copypaste]
----
heketi-cli device delete 01c94798bf6b1af87974573b420c4dff
----

You will see something like:

----
Device 01c94798bf6b1af87974573b420c4dff deleted
----

[NOTE]
====
Only devices that are not used by other Gluster volumes can be deleted. If
that's not the case `heketi-cli` will tell you about it. In this case you need
to issue a `remove` operation before.
====

You can now check that the device is gone from the topology by running:

----
heketi-cli topology info
----

Node deletion is also possible and is basically comprised of:

1. successful execution of the `remove` operation on all devices of the node
2. running `heketi-cli node delete <node_id>` on the node in question

### Running the OpenShift Registry with CNS

The Registry in OpenShift is a critical component. As it is the default
destination for all container builds in the cluster, and is the source for
deploying applications built inside the cluster, being unavailable is a big
problem.

The internal registry runs as one or more *Pods* inside the OpenShift
environment. By default the registry uses local ephemeral storage in its *Pod*.
This means that any restarts or re-deployments or outages would cause all of the
built/pushed container images to be lost. Also, only having one registry
instance and/or one infrastructure node could cause temporary outages. So,
adding storage and scaling up the registry is a good idea.

[IMPORTANT]
====
Your cluster only has one infrastructure node. In practice, you would want a
minimum of two to achieve high-availability for all infrastructure services.
====

#### Adding CNS to the Registry
Adding storage to the registry is as easy as it was for our file-uploader
application. Simply make the registry *Pods* use a PVC in access mode *RWX*
based on CNS. This way, a highly-available scale-out registry can be provided
without external dependencies on NFS or Cloud Provider storage.

[IMPORTANT]
====
The following method will be disruptive. All data stored in the registry so far
will be lost (the Rails and PHP app images). Migration scenarios exist but are
beyond the scope of this lab, but normally you would configure persistent
storage for the registry before starting to really use your cluster.
====

Make sure you are logged in as `system:admin` in the `default` namespace:

----
oc login -u system:admin -n default
----

Just like with the file uploader example, you can simply add a volume (and have
its *PersistentVolumeClaim* created automatically) with the `oc volume` command.
Execute the following:

----
oc volume dc/docker-registry --add --name=registry-storage -t pvc \
--claim-mode=ReadWriteMany --claim-size=5Gi \
--claim-name=registry-storage --overwrite
----

The registry will now redeploy.

[NOTE]
====
The registry is preconfigured with a volume called `registry-storage` that is
using the `emptyDir` storage type. The above command `--overwrite` the existing
volume with our new PVC. More information can be found in the
link:https://docs.openshift.com/container-platform/3.9/dev_guide/volumes.html[volumes
documentation^].
====

[TIP]
====
In a future release of OpenShift, you will be able to configure Container Native
Storage as part of the OpenShift installation directly, including automatically
using CNS for the storage for the registry, fully supported.
====

Observe the registry deployment get updated:

----
oc get pod -w
----

Remember to kbd:[Ctrl + c] when you are done watching the *Pods* redeploy.

After a couple of seconds a new deployment of the registry should be available.
Verify a new version of the registry's *DeploymentConfig* is running:

----
oc get dc/docker-registry
----

You will see something like:

----
NAME              REVISION   DESIRED   CURRENT   TRIGGERED BY
docker-registry   2          1         1         config
----

Now your OpenShift Registry is using persistent storage provided by CNS.  Since
this is shared storage this also allows you to scale out the registry pods.

You can scale the registry like this:

----
oc scale dc/docker-registry --replicas=3
----

After a short while you should see 3 healthy registry pods in the default
*Project*:

----
oc get pods
----

And you should see something like:

----
NAME                       READY     STATUS    RESTARTS   AGE
docker-registry-2-5rszg    1/1       Running   0          1m
docker-registry-2-7s3tm    1/1       Running   0          14s
docker-registry-2-g3l70    1/1       Running   0          14s
registry-console-1-b47jt   1/1       Running   0          6h
router-1-hs9wp             1/1       Running   0          6h
----
